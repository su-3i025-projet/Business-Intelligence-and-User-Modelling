{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0911a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "655c37b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_initializer(num_bins=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    bin_dict = {}\n",
    "    for i in range(num_bins):\n",
    "        bin_dict[i] = {}\n",
    "        bin_dict[i]['count'] = 0 # number of samples in the bin \n",
    "        bin_dict[i]['conf'] = 0 # sum of the bin's samples confidence \n",
    "        bin_dict[i]['acc'] = 0 # sum of the bin's samples accuracy \n",
    "        bin_dict[i]['bin_acc'] = 0 # average accuracy \n",
    "        bin_dict[i]['bin_conf'] = 0 # average confidence \n",
    "    return bin_dict  \n",
    "\n",
    "def populate_bins(confs, preds, labels, num_bins=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    bin_dict = bin_initializer(num_bins)\n",
    "    num_test_samples = len(confs)\n",
    "\n",
    "    for i in range(0, num_test_samples):\n",
    "        confidence = confs[i]\n",
    "        prediction = preds[i]\n",
    "        label = labels[i]\n",
    "        # find the right bin for sample i\n",
    "        binn = int(math.ceil(((num_bins * confidence) - 1)))\n",
    "        bin_dict[binn]['count'] += 1\n",
    "        bin_dict[binn]['conf'] += confidence\n",
    "        bin_dict[binn]['acc'] += (1 if (label == prediction) else 0)\n",
    "\n",
    "    for binn in range(0, num_bins):\n",
    "        if (bin_dict[binn]['count'] > 0):\n",
    "            bin_dict[binn]['bin_acc'] = bin_dict[binn]['acc']/\\\n",
    "                                        bin_dict[binn]['count']\n",
    "            bin_dict[binn]['bin_conf'] = bin_dict[binn]['conf']/\\\n",
    "                                        bin_dict[binn]['count']\n",
    "    return bin_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c855bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'count': 3,\n",
       "  'conf': 0.8,\n",
       "  'acc': 2,\n",
       "  'bin_acc': 0.6666666666666666,\n",
       "  'bin_conf': 0.26666666666666666},\n",
       " 1: {'count': 1, 'conf': 0.8, 'acc': 1, 'bin_acc': 1.0, 'bin_conf': 0.8}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_initializer(num_bins=2)\n",
    "populate_bins(confs=[0.1,0.2,0.5,0.8], preds=[1,0,0,0], labels=[1,1,0,0], num_bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8bfce900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected_calibration_error(confs, preds, labels, num_bins=10):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    bin_dict = populate_bins(confs, preds, labels, num_bins)\n",
    "    num_samples = len(labels)\n",
    "    ece = 0\n",
    "    for i in range(num_bins):\n",
    "        ece += (bin_dict[i]['count'] / num_samples) * \\\n",
    "        abs(bin_dict[i]['bin_acc'] - bin_dict[i]['bin_conf'])\n",
    "    return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c4561fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_calibration_error(confs=[0.1,0.2,0.5,0.8], preds=[1,0,0,0], labels=[1,1,0,0], num_bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36256048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximum_calibration_error(confs, preds, labels, num_bins=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    bin_dict = populate_bins(confs, preds, labels, num_bins)\n",
    "    ce = []\n",
    "    for i in range(num_bins):\n",
    "        ce.append(abs(bin_dict[i]['bin_acc'] - bin_dict[i]['bin_conf']))\n",
    "    return max(ce)\n",
    "\n",
    "def average_calibration_error(confs, preds, labels, num_bins=10):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    bin_dict = populate_bins(confs, preds, labels, num_bins)\n",
    "    non_empty_bins = 0\n",
    "    ace = 0\n",
    "    for i in range(num_bins):\n",
    "        if bin_dict[i]['count'] > 0:\n",
    "            non_empty_bins += 1\n",
    "        ace += abs(bin_dict[i]['bin_acc'] - bin_dict[i]['bin_conf'])\n",
    "    return ace / float(non_empty_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aab266d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39999999999999997"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum_calibration_error(confs=[0.1,0.2,0.5,0.8], preds=[1,0,0,0], labels=[1,1,0,0], num_bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d837f961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29999999999999993"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_calibration_error(confs=[0.1,0.2,0.5,0.8], preds=[1,0,0,0], labels=[1,1,0,0], num_bins=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "437d7fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classification_net_logits(logits, labels):\n",
    "    '''\n",
    "    This function reports classification accuracy and confusion matrix given logits and labels\n",
    "    from a model.\n",
    "    '''\n",
    "    labels_list = []\n",
    "    predictions_list = []\n",
    "    confidence_vals_list = []\n",
    "\n",
    "    softmax = F.softmax(logits, dim=1)\n",
    "    confidence_vals, predictions = torch.max(softmax, dim=1)\n",
    "    labels_list.extend(labels.cpu().numpy().tolist())\n",
    "    predictions_list.extend(predictions.cpu().numpy().tolist())\n",
    "    confidence_vals_list.extend(confidence_vals.cpu().numpy().tolist())\n",
    "    accuracy = accuracy_score(labels_list, predictions_list)\n",
    "    return confusion_matrix(labels_list, predictions_list), accuracy, labels_list,\\\n",
    "        predictions_list, confidence_vals_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6b38041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[2, 0],\n",
       "        [0, 2]]),\n",
       " 1.0,\n",
       " [1, 1, 0, 0],\n",
       " [1, 1, 0, 0],\n",
       " [0.622459352016449,\n",
       "  0.6456562876701355,\n",
       "  0.5986876487731934,\n",
       "  0.6456562876701355])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_classification_net_logits(logits=torch.tensor([[0.1,0.6],[0.2,0.8],[0.5,0.1],[0.8,0.2]]), \\\n",
    "                               labels=torch.tensor([1,1,0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2829a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECELoss(nn.Module):\n",
    "    '''\n",
    "    Compute ECE (Expected Calibration Error)\n",
    "    '''\n",
    "    def __init__(self, n_bins=15):\n",
    "        super(ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        \n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(bin_boundaries[:-1], bin_boundaries[1:]):\n",
    "            # Compute |confidence - accuracy| * (#bin / #samples) in each bin\n",
    "            \n",
    "            # Find the samples that belong to the bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            \n",
    "            # If the bin isn't empty\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean() # Bin accuracy \n",
    "                avg_confidence_in_bin = confidences[in_bin].mean() # Bin confidence\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "                \n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39a34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveECELoss(nn.Module):\n",
    "    '''\n",
    "    Compute Adaptive ECE\n",
    "    '''\n",
    "    def __init__(self, n_bins=15):\n",
    "        super(AdaptiveECELoss, self).__init__()\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "    def histedges_equalN(self, x):\n",
    "        npt = len(x)\n",
    "        return np.interp(np.linspace(0, npt, self.n_bins + 1),\n",
    "                     np.arange(npt),\n",
    "                     np.sort(x))\n",
    "    def forward(self, logits, labels):\n",
    "        \n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        \n",
    "        n, bin_boundaries = np.histogram(confidences.cpu().detach(), self.histedges_equalN(confidences.cpu().detach()))\n",
    "        \n",
    "        #print(n,confidences,bin_boundaries)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f31ac4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=torch.tensor([[0.1,0.6],[0.2,0.8],[0.5,0.1],[0.8,0.2]])\n",
    "labels=torch.tensor([1,1,0,0])\n",
    "\n",
    "softmaxes = F.softmax(logits, dim=1)\n",
    "confidences, predictions = torch.max(softmaxes, 1)\n",
    "accuracies = predictions.eq(labels)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da977f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
